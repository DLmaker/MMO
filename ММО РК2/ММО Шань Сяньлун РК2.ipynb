{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca0bcc6",
   "metadata": {},
   "source": [
    "# Рубежный контроль №2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e7889a",
   "metadata": {},
   "source": [
    "# Тема: Методы обработки текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976a99c0",
   "metadata": {},
   "source": [
    "# Решение задачи классификации текстов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f87255c",
   "metadata": {},
   "source": [
    "Необходимо решить задачу классификации текстов на основе любого выбранного Вами датасета (кроме примера, который рассматривался в лекции). Классификация может быть бинарной или многоклассовой. Целевой признак из выбранного Вами датасета может иметь любой физический смысл, примером является задача анализа тональности текста.\n",
    "\n",
    "Необходимо сформировать два варианта векторизации признаков - на основе CountVectorizer и на основе TfidfVectorizer.\n",
    "\n",
    "В качестве классификаторов необходимо использовать два классификатора по варианту для Вашей группы:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56013f1c",
   "metadata": {},
   "source": [
    " ИУ5И-22М \n",
    " \n",
    " Классификатор №1:RandomForestClassifier\n",
    " \n",
    " Классификатор №2: Complement Naive Bayes - CNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c422163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be7c1e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JLZlCZ0</td>\n",
       "      <td>Ep 1| Travelling through North East India | Of...</td>\n",
       "      <td>Tanya Khanijow\\n671K subscribers\\nSUBSCRIBE\\nT...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i9E_Blai8vk</td>\n",
       "      <td>Welcome to Bali | Travel Vlog | Priscilla Lee</td>\n",
       "      <td>Priscilla Lee\\n45.6K subscribers\\nSUBSCRIBE\\n*...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r284c-q8oY</td>\n",
       "      <td>My Solo Trip to ALASKA | Cruising From Vancouv...</td>\n",
       "      <td>Allison Anderson\\n588K subscribers\\nSUBSCRIBE\\...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Qmi-Xwq-ME</td>\n",
       "      <td>Traveling to the Happiest Country in the World!!</td>\n",
       "      <td>Yes Theory\\n6.65M subscribers\\nSUBSCRIBE\\n*BLA...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_lcOX55Ef70</td>\n",
       "      <td>Solo in Paro Bhutan | Tiger's Nest visit | Bhu...</td>\n",
       "      <td>Tanya Khanijow\\n671K subscribers\\nSUBSCRIBE\\nH...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>21st Century Challenges: Crash Course European...</td>\n",
       "      <td>CrashCourse\\n12.4M subscribers\\nSUBSCRIBE\\nThe...</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>d-2Trw8bCa0</td>\n",
       "      <td>EU DataViz webinar - Barnaby Skinner - How to ...</td>\n",
       "      <td>Publications Office of the European Union\\n3.2...</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>RCKWarkUL</td>\n",
       "      <td>Stone Age Scandinavia: First People In the Nor...</td>\n",
       "      <td>History Time\\n619K subscribers\\nSUBSCRIBE\\n- W...</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>MF6F3BxJIY</td>\n",
       "      <td>AP European History - Interwar Period: Paris P...</td>\n",
       "      <td>Mr. Raymond's Civics and Social Studies Academ...</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3598</th>\n",
       "      <td>lByKodp_UK</td>\n",
       "      <td>World War 2 Allied Conferences: AP European Hi...</td>\n",
       "      <td>Paul Sargent\\n25.3K subscribers\\nSUBSCRIBE\\nIn...</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3599 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             link                                              title  \\\n",
       "0         JLZlCZ0  Ep 1| Travelling through North East India | Of...   \n",
       "1     i9E_Blai8vk      Welcome to Bali | Travel Vlog | Priscilla Lee   \n",
       "2      r284c-q8oY  My Solo Trip to ALASKA | Cruising From Vancouv...   \n",
       "3      Qmi-Xwq-ME   Traveling to the Happiest Country in the World!!   \n",
       "4     _lcOX55Ef70  Solo in Paro Bhutan | Tiger's Nest visit | Bhu...   \n",
       "...           ...                                                ...   \n",
       "3594       #NAME?  21st Century Challenges: Crash Course European...   \n",
       "3595  d-2Trw8bCa0  EU DataViz webinar - Barnaby Skinner - How to ...   \n",
       "3596    RCKWarkUL  Stone Age Scandinavia: First People In the Nor...   \n",
       "3597   MF6F3BxJIY  AP European History - Interwar Period: Paris P...   \n",
       "3598   lByKodp_UK  World War 2 Allied Conferences: AP European Hi...   \n",
       "\n",
       "                                            description category  \n",
       "0     Tanya Khanijow\\n671K subscribers\\nSUBSCRIBE\\nT...   travel  \n",
       "1     Priscilla Lee\\n45.6K subscribers\\nSUBSCRIBE\\n*...   travel  \n",
       "2     Allison Anderson\\n588K subscribers\\nSUBSCRIBE\\...   travel  \n",
       "3     Yes Theory\\n6.65M subscribers\\nSUBSCRIBE\\n*BLA...   travel  \n",
       "4     Tanya Khanijow\\n671K subscribers\\nSUBSCRIBE\\nH...   travel  \n",
       "...                                                 ...      ...  \n",
       "3594  CrashCourse\\n12.4M subscribers\\nSUBSCRIBE\\nThe...  history  \n",
       "3595  Publications Office of the European Union\\n3.2...  history  \n",
       "3596  History Time\\n619K subscribers\\nSUBSCRIBE\\n- W...  history  \n",
       "3597  Mr. Raymond's Civics and Social Studies Academ...  history  \n",
       "3598  Paul Sargent\\n25.3K subscribers\\nSUBSCRIBE\\nIn...  history  \n",
       "\n",
       "[3599 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('youtube.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dd4df3",
   "metadata": {},
   "source": [
    "# Предобработка признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f233cb6",
   "metadata": {},
   "source": [
    "TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5ee964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "看一下tfidf_ngram_features的值：\n",
      "  (0, 12865)\t0.026498899028004747\n",
      "  (0, 17321)\t0.026535936513009763\n",
      "  (0, 20222)\t0.056672786612321085\n",
      "  (0, 13443)\t0.10617413840216165\n",
      "  (0, 3349)\t0.12252855255981054\n",
      "  (0, 8237)\t0.08179721643009606\n",
      "  (0, 13898)\t0.0995092588291622\n",
      "  (0, 20734)\t0.07917522101745697\n",
      "  (0, 1836)\t0.12468252161298352\n",
      "  (0, 3846)\t0.20298293694881073\n",
      "  (0, 12184)\t0.14919309938125191\n",
      "  (0, 7423)\t0.13749638394983638\n",
      "  (0, 17661)\t0.07651065694772624\n",
      "  (0, 8905)\t0.07422251008358562\n",
      "  (0, 18941)\t0.07178710961660202\n",
      "  (0, 13773)\t0.044986203510332834\n",
      "  (0, 8349)\t0.1564895455085993\n",
      "  (0, 19154)\t0.1564895455085993\n",
      "  (0, 7291)\t0.13081629728384944\n",
      "  (0, 4045)\t0.06763707519445934\n",
      "  (0, 18012)\t0.12655743425241778\n",
      "  (0, 8241)\t0.13908983274384046\n",
      "  (0, 10527)\t0.10437382358177655\n",
      "  (0, 2487)\t0.06908816000418752\n",
      "  (0, 5028)\t0.20298293694881073\n",
      "  :\t:\n",
      "  (3598, 7766)\t0.07061592002524433\n",
      "  (3598, 928)\t0.10576974746171705\n",
      "  (3598, 5388)\t0.1116464597082773\n",
      "  (3598, 2134)\t0.07765312328577796\n",
      "  (3598, 9607)\t0.10402784484713663\n",
      "  (3598, 7812)\t0.08812866178590896\n",
      "  (3598, 9311)\t0.07265062864871628\n",
      "  (3598, 3168)\t0.06734810442320449\n",
      "  (3598, 19027)\t0.043524558473489114\n",
      "  (3598, 13880)\t0.04840345897219326\n",
      "  (3598, 20873)\t0.09841590144437862\n",
      "  (3598, 4024)\t0.07377923074840587\n",
      "  (3598, 9635)\t0.03851122907342391\n",
      "  (3598, 13613)\t0.07823235623580176\n",
      "  (3598, 12865)\t0.023813631633524963\n",
      "  (3598, 17321)\t0.02384691592294429\n",
      "  (3598, 20222)\t0.05092984665532338\n",
      "  (3598, 13898)\t0.08942548259753819\n",
      "  (3598, 17661)\t0.0687574453061848\n",
      "  (3598, 18941)\t0.12902511780874973\n",
      "  (3598, 4045)\t0.060783068449284224\n",
      "  (3598, 10527)\t0.09379709641265413\n",
      "  (3598, 18944)\t0.2119791529494695\n",
      "  (3598, 18247)\t0.021471690804779037\n",
      "  (3598, 18253)\t0.024968265048099708\n"
     ]
    }
   ],
   "source": [
    "tfidf=TfidfVectorizer()\n",
    "tfidf_ngram_features=tfidf.fit_transform(df['description'])\n",
    "print('看一下tfidf_ngram_features的值：\\n{}'.format(tfidf_ngram_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aefd5f4",
   "metadata": {},
   "source": [
    "CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58b2616c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "看一下countv_ngram_features的值：\n",
      "  (0, 18683)\t1\n",
      "  (0, 10848)\t1\n",
      "  (0, 1257)\t1\n",
      "  (0, 18253)\t1\n",
      "  (0, 18247)\t1\n",
      "  (0, 18944)\t3\n",
      "  (0, 10460)\t2\n",
      "  (0, 19187)\t4\n",
      "  (0, 2581)\t2\n",
      "  (0, 13596)\t1\n",
      "  (0, 6676)\t1\n",
      "  (0, 9691)\t1\n",
      "  (0, 3228)\t1\n",
      "  (0, 20776)\t1\n",
      "  (0, 19356)\t1\n",
      "  (0, 7951)\t4\n",
      "  (0, 8668)\t1\n",
      "  (0, 13037)\t1\n",
      "  (0, 9020)\t2\n",
      "  (0, 20580)\t2\n",
      "  (0, 8931)\t1\n",
      "  (0, 14334)\t1\n",
      "  (0, 2265)\t2\n",
      "  (0, 13094)\t1\n",
      "  (0, 19399)\t1\n",
      "  :\t:\n",
      "  (3598, 17314)\t1\n",
      "  (3598, 6610)\t1\n",
      "  (3598, 19005)\t3\n",
      "  (3598, 20646)\t1\n",
      "  (3598, 16784)\t1\n",
      "  (3598, 7757)\t1\n",
      "  (3598, 5452)\t2\n",
      "  (3598, 11466)\t1\n",
      "  (3598, 581)\t1\n",
      "  (3598, 4911)\t1\n",
      "  (3598, 8992)\t1\n",
      "  (3598, 15084)\t1\n",
      "  (3598, 20506)\t3\n",
      "  (3598, 7864)\t1\n",
      "  (3598, 14426)\t1\n",
      "  (3598, 14390)\t1\n",
      "  (3598, 17144)\t1\n",
      "  (3598, 7886)\t1\n",
      "  (3598, 7862)\t1\n",
      "  (3598, 5113)\t2\n",
      "  (3598, 16710)\t1\n",
      "  (3598, 20531)\t1\n",
      "  (3598, 2098)\t1\n",
      "  (3598, 14938)\t1\n",
      "  (3598, 5734)\t1\n"
     ]
    }
   ],
   "source": [
    "countv=CountVectorizer()\n",
    "countv_ngram_features=countv.fit_transform(df['description'])\n",
    "print('看一下countv_ngram_features的值：\\n{}'.format(countv_ngram_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea4eaaa",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bd90913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      travel     0.9423    0.9142    0.9280       268\n",
      "   art_music     0.9364    0.8371    0.8840       264\n",
      "        food     0.9664    0.8136    0.8834       177\n",
      "     history     0.8046    0.9434    0.8685       371\n",
      "\n",
      "    accuracy                         0.8889      1080\n",
      "   macro avg     0.9124    0.8771    0.8910      1080\n",
      "weighted avg     0.8975    0.8889    0.8895      1080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TFIDF + RFC\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_ngram_features, df['category'], test_size=0.3, random_state=1)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=4, target_names=list(map(str, list(y_test.unique())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44e27843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      travel     0.9504    0.9291    0.9396       268\n",
      "   art_music     0.9573    0.8485    0.8996       264\n",
      "        food     0.9603    0.8192    0.8841       177\n",
      "     history     0.8199    0.9569    0.8831       371\n",
      "\n",
      "    accuracy                         0.9009      1080\n",
      "   macro avg     0.9219    0.8884    0.9016      1080\n",
      "weighted avg     0.9088    0.9009    0.9013      1080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CountVec + RFC\n",
    "X_train, X_test, y_train, y_test = train_test_split(countv_ngram_features, df['category'], test_size=0.3, random_state=1)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=4, target_names=list(map(str, list(y_test.unique())))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bb6647",
   "metadata": {},
   "source": [
    "# Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d302ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      travel     0.8905    0.9403    0.9147       268\n",
      "   art_music     0.9587    0.8788    0.9170       264\n",
      "        food     0.9023    0.8870    0.8946       177\n",
      "     history     0.9081    0.9326    0.9202       371\n",
      "\n",
      "    accuracy                         0.9139      1080\n",
      "   macro avg     0.9149    0.9097    0.9116      1080\n",
      "weighted avg     0.9151    0.9139    0.9139      1080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TFIDF + CNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_ngram_features, df['category'], test_size=0.3, random_state=1)\n",
    "model = ComplementNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=4, target_names=list(map(str, list(y_test.unique())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b85bd02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      travel     0.9029    0.9366    0.9194       268\n",
      "   art_music     0.9283    0.8826    0.9049       264\n",
      "        food     0.8595    0.8983    0.8785       177\n",
      "     history     0.9235    0.9111    0.9172       371\n",
      "\n",
      "    accuracy                         0.9083      1080\n",
      "   macro avg     0.9035    0.9071    0.9050      1080\n",
      "weighted avg     0.9091    0.9083    0.9084      1080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CountVec + CNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(countv_ngram_features, df['category'], test_size=0.3, random_state=1)\n",
    "model = ComplementNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=4, target_names=list(map(str, list(y_test.unique())))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1977f9",
   "metadata": {},
   "source": [
    "# Выводы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ba1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
